#+TITLE: DataAnalysis For Python
#+KEYWORDS: data analysis, python
#+OPTIONS: H:4 toc:2 num:3 ^:nil
#+LaTeX: t
#+LANGUAGE: en-US
#+AUTHOR: ChrisChen
#+EMAIL: ChrisChen3121@gmail.com
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+SETUPFILE: ../../org-templates/level-1.org
* numpy
** ndarray
   #+BEGIN_SRC python
     import numpy as np
     py_array = [1, 2, 3, 4, 5]
     np_array = np.array(py_array)
     np_array.shape #=> (5,)
     np_array.dtype #=> dtype('int64')

     py_array = [[1, 2, 3, 4], [5, 6, 7, 8]]
     np_array = np.array(py_array)
     np_array.shape #=> (2, 4)
     np_array.ndim #=> 2

     np.zeros(10)
     #=> array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])
     np.ones((2, 3))
     #=> array([[ 1.,  1.,  1.], [ 1.,  1.,  1.]])
     np.empty((2, 3, 2))
     #=>
     # array([[[ 0.,  0.],
     #         [ 0.,  0.],
     #         [ 0.,  0.]],

     #        [[ 0.,  0.],
     #         [ 0.,  0.],
     #         [ 0.,  0.]]])

     np.arange(5)
     #=> array([0, 1, 2, 3, 4])
     np.random.randn(2, 3)

     np_array = np.array([1, 2, 3], dtype=np.int32)
     np_array = np_array.astype(np.float64)
     np_array.dtype #=> dtype('float64')
   #+END_SRC

- Creation

  | Function          | Description                                                                                                                                                                   |
  |-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
  | array             | Convert input data (list, tuple, array, or other sequence type) to an ndarray either by inferring a dtype or explicitly specifying a dtype. Copies the input data by default. |
  | asarray           | Convert input to ndarray, but do not copy if the input is already an ndarray                                                                                                  |
  | arange            | Like the built-in range but returns an ndarray instead of a list                                                                                                              |
  | ones, ones_like   | Produce an array of all 1’s with the given shape and dtype, ones_like takes another array and produces a ones array of the same shape and dtype.                             |
  | zeros, zeros_like | Like ones and ones_like but producing arrays of 0’s instead                                                                                                                  |
  | empty, empty_like | Create new arrays by allocating new memory, but do not populate with any values like ones and zeros                                                                           |
  | eye, identity     | Create a square N x N identity matrix (1’s on the diagonal and 0’s elsewhere)                                                                                               |

- Supported dtype

  int8, uint8, int16, uint16, int32, uint32, int64, uint64,
  float16, float32, float64, float128
  complex64, complex128, complex256
  bool
  object
  string_
  unicode_

*** Creating
    | Function          | Description                                                                     |
    |-------------------+---------------------------------------------------------------------------------|
    | array             | Convert input data (list, tuple, array, or other sequence type) to an ndarray   |
    | asarray           | Convert input to ndarray, but do not copy if the input is already an ndarray    |
    | arange            | Like the built-in range but returns an ndarray instead of a list.               |
    | ones, ones_like   | Produce an array of all 1’s with the given shape and dtype.                    |
    | zeros, zeros_like | Produce an array of all 0’s with the given shape and dtype.                    |
    | empty, empty_like | Create new arrays by allocating new memory                                      |
    | eye, identity     | Create a square N x N identity matrix (1’s on the diagonal and 0’s elsewhere) |
*** Indexing
    <<numpy indexing>>
**** basic indexing

    #+BEGIN_SRC python
      arr = np.array(range(12)).reshape(3,4)
      # array([[ 0,  1,  2,  3],
      #        [ 4,  5,  6,  7],
      #        [ 8,  9, 10, 11]])

      arr[1:, :3]
      # array([[ 4,  5,  6],
      #        [ 8,  9, 10]])
    #+END_SRC
**** boolean indexing
  #+BEGIN_SRC python
    flags = np.array([1, 2, 3, 2, 2, 1])
    data = np.random.randn(6,2)
    # array([[ 2.11684529,  1.24861544],
    #        [-0.34817586, -0.59905366],
    #        [-0.84976431,  0.11840417],
    #        [ 1.36648373,  1.33416664],
    #        [ 0.37616856, -0.0032112 ],
    #        [-0.7749904 , -0.60457688]])
    flags ==2
    # array([False,  True, False,  True,  True, False], dtype=bool)
    data[flags == 2]
    # array([[-0.34817586, -0.59905366],
    #        [ 1.36648373,  1.33416664],
    #        [ 0.37616856, -0.0032112 ]])
    data[(flags == 3) | (flags == 1), 1:]
    # array([[ 1.24861544],
    #        [ 0.11840417],
    #        [-0.60457688]])
    data[data<0] = 0
    # array([[ 2.11684529,  1.24861544],
    #        [ 0.        ,  0.        ],
    #        [ 0.        ,  0.11840417],
    #        [ 1.36648373,  1.33416664],
    #        [ 0.37616856,  0.        ],
    #        [ 0.        ,  0.        ]])
  #+END_SRC
**** fancy indexing
  #+BEGIN_VERSE
  Fancy indexing is a term adopted by NumPy to describe indexing using *integer arrays* .
  Unlike slicing, =always copies the data into a new array= .
  #+END_VERSE
  #+BEGIN_SRC python
    arr
    # array([[ 0.,  0.,  0.,  0.],
    #        [ 1.,  1.,  1.,  1.],
    #        [ 2.,  2.,  2.,  2.]])
    arr[[2, 1]]
    # array([[ 2.,  2.,  2.,  2.],
    #        [ 1.,  1.,  1.,  1.]])
    arr = np.array(range(12)).reshape(3,4)
    # array([[ 0,  1,  2,  3],
    #        [ 4,  5,  6,  7],
    #        [ 8,  9, 10, 11]])
    arr[[1,2], [2,3]]
    # array([ 6, 11]) # choose location (1, 2) (2, 3)

    arr[[1,2]][:, [2,3]]
    # array([[ 6,  7],
    #        [10, 11]])
    arr[np.ix_([1,2], [2,3])] # same effect
    # array([[ 6,  7],
    #        [10, 11]])
  #+END_SRC
** Conditional Logic
*** any, all
*** numpy.where
    The *numpy.where* function is a vectorized version of the ternary expression x if
    condition else y. *numpy.where* is quicker than list comprehension.
#+BEGIN_SRC python
  xarr = np.array([1,1,1,1,1])
  yarr = np.array([2,2,2,2,2])
  cond = np.array([True, False, True, False, False])
  np.where(cond, xarr, yarr)
  # array([1, 2, 1, 2, 2])
  np.where(cond, 4, 3)
  # array([4, 3, 4, 3, 3])
#+END_SRC

** Transpose
   Simple transposing with =.T= is just a special case of =swapaxes=

** Useful functions
*** Math
    | Method         | Description                                                                                |
    |----------------+--------------------------------------------------------------------------------------------|
    | sign           | Returns on array of 1 and -1 depending on the sign of the values                           |
    | sum            | Sum of all the elements in the array or along an axis. Zero-length arrays have sum 0       |
    | mean           | Arithmetic mean. Zero-length arrays have NaN mean                                          |
    | std, var       | Standard deviation and variance, respectively, with optional degrees of freedom adjustment |
    | min, max       | Minimum and maximum                                                                        |
    | argmin, argmax | Indices of minimum and maximum elements, respectively                                      |
    | cumsum         | Cumulative sum of elements starting from 0                                                 |
    | cumprod        | Cumulative product of elements starting from 1                                             |
    | abs, fabs      | Use *fabs* as a faster alternative for non-complex-valued data                             |
    | modf           | Return factional and integral parts of array as separate array                             |
    | rint           | Round elements to the nearest integer, preserving the dtype                                |
    | average        | Compute the weighted average along the specified axis.                                     |
*** Linear Algebra
    | Function | Description                                                         |
    |----------+---------------------------------------------------------------------|
    | diag     | Return the diagonal (or off-diagonal) elements of a square matrix   |
    | dot      | *Matrix multiplication*                                             |
    | trace    | Compute the sum of the diagonal elements                            |
    | det      | Compute the matrix determinant                                      |
    | eig      | Compute the eigenvalues and eigenvectors of a square matrix         |
    | inv      | Compute the inverse of a square matrix                              |
    | pinv     | Compute the Moore-Penrose pseudo-inverse inverse of a square matrix |
    | qr       | Compute the QR decomposition                                        |
    | svd      | Compute the singular value decomposition (SVD)                      |
    | solve    | Solve the linear system Ax = b for x, where A is a square matrix    |
    | lstsq    | Compute the least-squares solution to y = Xb                        |
*** Random Number Generation
    | Function    | Description                                                                                          |
    |-------------+------------------------------------------------------------------------------------------------------|
    | seed        | Seed the random number generator                                                                     |
    | permutation | Return a random permutation of a sequence, or return a permuted range                                |
    | shuffle     | Randomly permute a sequence in place                                                                 |
    | rand        | Draw samples from a uniform distribution                                                             |
    | randint     | Draw random integers from a given low-to-high range                                                  |
    | randn       | Draw samples from a normal distribution with mean 0 and standard deviation 1 (MATLAB-like interface) |
    | binomial    | Draw samples a binomial distribution                                                                 |
    | normal      | Draw samples from a normal (Gaussian) distribution                                                   |
    | beta        | Draw samples from a beta distribution                                                                |
    | chisquare   | Draw samples from a chi-square distribution                                                          |
    | gamma       | Draw samples from a gamma distribution                                                               |
    | uniform     | Draw samples from a uniform [0, 1) distribution                                                      |
*** Set operations
    | Function          | Description                                                                        |
    |-------------------+------------------------------------------------------------------------------------|
    | unique(x)         | Compute the sorted, unique elements in x                                           |
    | intersect1d(x, y) | Compute the sorted, common elements in x and y                                     |
    | union1d(x, y)     | Compute the sorted union of elements                                               |
    | in1d(x, y)        | Compute a boolean array indicating whether element of x is in y                    |
    | setdiff1d(x, y)   | Set difference, elements in x that are not in y                                    |
    | setxor1d(x, y)    | Set symmetric differences; elements that are in either of the arrays, but not both |
* pandas
** Series
   Series is a fixed-length *ordered dict*
** DataFrame
#+BEGIN_SRC python
  df = pd.DataFrame(np.arange(8).reshape(4,2),
                    columns=['c1', 'c2'], index=['r1', 'r2', 'r3', 'r4'])

  df.ix['r1'] # retrieve row
  # c1    0
  # c2    1
  # Name: r1, dtype: int64

  df.ix[['r1','r2']]
  #     c1  c2
  # r1   0   1
  # r2   2   3

  df.T
  #     r1  r2  r3  r4
  # c1   0   2   4   6
  # c2   1   3   5   7

  del df['c2']

  df.columns
  # Index([u'c1'], dtype='object')
#+END_SRC
** Indexing Options
   - Common use: =obj[val], obj.ix[val], obj.ix[:, val], obj.ix[val1, val2], reindex=
   - Others:

     | Type                  | Notes                                                                      |
     |-----------------------+----------------------------------------------------------------------------|
     | xs                    | Select single row or column as a Series by label                           |
     | icol, irow, iloc, iat | Select single column or row, respectively, as a Series by integer location |
     | get_value, set_value  | Select single value by row and column label                                |
*** difference
    - loc: only work on index
    - iloc: work on position
    - ix: can get data from dataframe without it being in the index
    - at: get scalar values. It's a very fast loc
    - iat: get scalar values. It's a very fast iloc

** Index
   Index objects are immutable, functions as a fixed-size set.
   - main type: =Index, Int64Index, MultiIndex, DatetimeIndex, PeriodIndex=

   | Method       | Description                                                                               |
   |--------------+-------------------------------------------------------------------------------------------|
   | append       | Concatenate with additional Index objects, producing a new Index                          |
   | diff         | Compute set difference as an Index                                                        |
   | intersection | Compute set intersection                                                                  |
   | union        | Compute set union                                                                         |
   | isin         | Compute boolean array indicating whether each value is contained in the passed collection |
   | delete       | Compute new Index with element at index i deleted                                         |
   | drop         | Compute new index by deleting passed values                                               |
   | insert       | Compute new Index by inserting element at index i                                         |
   | is_monotonic | Returns True if each element is greater than or equal to the previous element             |
   | is_unique    | Returns True if the Index has no duplicate values                                         |
   | unique       | Compute the array of unique values in the Index                                           |
** Functionality
*** Reindexing
Example:
#+BEGIN_SRC python
  frame.reindex(columns=['c1', 'c2'])
  frame.reindex(index=['a', 'b', 'c', 'd'], method='ffill', columns=['c1', 'c2'])
  # is similar to frame.ix[['a', 'b', 'c', 'd'], ['c1', 'c2']]
#+END_SRC
reindex args: index, method, fill_value, limit, level, copy
*** Drop
#+BEGIN_SRC python
  frame.drop(['r1', 'r2'])
  frame.drop(['c1', 'c2'], axis=1)
#+END_SRC
*** Selection
    See [[numpy indexing]].

*** Arithmetic
    - Basic df1 + df2,
    - use add method to fill na values: df1.add(df2, fill_value=0)

- Operation between Dataframe and Series
#+BEGIN_SRC python
  df = pd.DataFrame(np.arange(6).reshape(3,2),
                    columns=['c1', 'c2'], index=['r1', 'r2', 'r3'])

  #     c1  c2
  # r1   0   1
  # r2   2   3
  # r3   4   5

  s = pd.Series([4,5], index=['c1', 'c2'])

  # c1    4
  # c2    5
  # dtype: int64

  df + s
  #     c1  c2
  # r1   4   6
  # r2   6   8
  # r3   8  10


  s2 = pd.Series([1,2,3], index=['r1', 'r2', 'r3'])
  # r1    1
  # r2    2
  # r3    3
  # dtype: int64

  df.add(s2, axis=0)
  #     c1  c2
  # r1   1   2
  # r2   4   5
  # r3   7   8
#+END_SRC
*** Broadcasting
    #+BEGIN_SRC python
      frame=pd.DataFrame(np.arange(12).reshape((4,3)), columns=list('bde'), index=list('1234'))
      series = frame.ix[0]
      frame - series
      #=>
      #    b  d  e
      # 1  0  0  0
      # 2  3  3  3
      # 3  6  6  6
      # 4  9  9  9

      series2 = pd.Series(range(3), index=list('bef'))
      frame + series2
      #=>
      #      b   d     e   f
      # 1  0.0 NaN   3.0 NaN
      # 2  3.0 NaN   6.0 NaN
      # 3  6.0 NaN   9.0 NaN
      # 4  9.0 NaN  12.0 NaN
    #+END_SRC
*** Apply
    #+BEGIN_SRC python
      f = lambda x: x.max()
      frame.apply(f)
      frame.apply(f, axis=1)
    #+END_SRC
    *apply* can also return a series
    #+BEGIN_SRC python
      def f(x):
          return pd.Series([x.min(), x.max()], index=['min', 'max'])
      frame.apply(f)
      #=>    a   b
      # min xxx xxx
      # max xxx xxx
    #+END_SRC
*** Sort
  #+BEGIN_SRC python
    df.sort_index()

    # by column(s)
    df.sort_index(by='c1')
    df.sort_index(by=['c1', 'c2'])
  #+END_SRC
*** Rank
    args: 'average'(default), 'min', 'max', 'first'
    #+BEGIN_SRC python
      obj = pd.Series([7, -5, 7, 4, 2, 0, 4, 7])
      obj.rank()
      #=>
      # 0    7.0
      # 1    1.0
      # 2    7.0
      # 3    4.5
      # 4    3.0
      # 5    2.0
      # 6    4.5
      # 7    7.0
      obj.rank(method='first')
      #=>
      # 0    6.0
      # 1    1.0
      # 2    7.0
      # 3    4.0
      # 4    3.0
      # 5    2.0
      # 6    5.0
      # 7    8.0
    #+END_SRC

*** Other funtions
- numpy *ufancs* works fine with pandas objects
- applymap(element-wise), map(series element-wise)
- order(for series sorting): s.order()
- isnull, notnull, dropna, fillna
- stack, unstack, swaplevel, sortlevel
- set_index, reset_index
- unique(series based), value_counts(series based), isin(element-wise)
- all, any
- replace
- cut, qcut

** Statistic methods
   Basic:
   count, describe, min, max, quantile, sum, pct_change, diff, corr, cov, corrwith

*** mean, median, mad, var, std
*** argmin, argmax, idxmin, idxmax

    argmin/argmax: compute index locations (integers) at which minimum or maximum value obtained, respectively

*** cumsum, cummin, cummax, cumprod
*** skew

    Sample skewness (3rd moment) of values

*** kurt

    Sample kurtosis (4th moment) of values

*** diff

    Compute 1st arithmetic difference (useful for time series)

*** corr, cov, corrwith
    #+BEGIN_SRC python
      import pandas_datareader as pdr

      all_data = {}
      for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG']:
          all_data[ticker] = pdr.get_data_yahoo(ticker, '1/1/2000', '1/1/2010')

      price = pd.DataFrame({tic: data['Adj Close'] for tic, data in all_data.iteritems()})
      returns = price.pct_change()

      returns.MSFT.corr(returns.IBM)
      returns.MSFT.cov(returns.IBM)

      returns.corr()
      returns.corrwith(returns.IBM)
    #+END_SRC

*** common args
     | Method | Description                                                                |
     |--------+----------------------------------------------------------------------------|
     | axis   | Axis to reduce over. 0 for DataFrame’s rows and 1 for columns             |
     | skipna | Exclude missing values, True by default                                    |
     | level  | Reduce grouped by level if the axis is hierarchically-indexed (MultiIndex) |

     *skipna* option:
     - True(default): NA values are excluded unless the entire slice (row or column in this case) is NA
     - False: if any value is *NA*, then return *NA*

** Hierarchical Indexing
*** Indexing
    #+BEGIN_SRC example
      data[index_level1]
      data[index_level1 : index_level1]
      data[[index_level1, index_level1]]

      select by inner level:
      data[:, index_level2]
    #+END_SRC
*** stack, unstack
*** swaplevel, sortlevel
** Panel
   Panel can be thought as a 3-dimensional analogue of DataFrame.
   Although hierarchical indexing makes using truly N-dimensional arrays unnecessary in a lot of cases
   #+BEGIN_SRC python
     pdata = pd.Panel({stk: pdr.get_data_yahoo(stk, '1/1/2009', '6/1/2012')
                       for stk in ['AAPL', 'GOOG']})

   #+END_SRC
*** Useful functions
    - ix
      #+BEGIN_SRC python
        pdata.ix[:, '6/1/2012', :]
      #+END_SRC
    - swapaxes
      #+BEGIN_SRC python
        pdata.swapaxes('items', 'minor')['Adj Close']
      #+END_SRC
    - to_frame

      index will be the *[major, minor]* axis, *items* will be the columns
      #+BEGIN_SRC python
        stacked = pdata.to_frame()
      #+END_SRC

    - to_panel
      #+BEGIN_SRC python
        stacked.to_panel()
      #+END_SRC

** TimeSeries
*** numpy.datatime64
    nanoseconds resolution.
    pandas *stores* timestamps as numpy.datatime64
*** pandas *Timestamp*
**** timezone-aware
**** to_period
*** Frequencies
    #+CAPTION: Base Time Series Frequencies
    | Alias               | Offset Type          |
    |---------------------+----------------------|
    | D                   | Day                  |
    | B                   | BusinessDay          |
    | H                   | Hour                 |
    | T or min            | Minute               |
    | S                   | Second               |
    | L or ms             | Milli                |
    | U                   | Micro                |
    | M                   | MonthEnd             |
    | BM                  | BusinessMonthEnd     |
    | MS                  | MonthBegin           |
    | BMS                 | BusinessMonthBegin   |
    | W-Mon, W-TUE, ...   | Week                 |
    | WOM-1MON, ...       | WeekOfMonth          |
    | Q-JAN, Q-FEB, ...   | QuarterEnd           |
    | BQ-JAN, BQ-FEB, ... | BusinessQuarterEnd   |
    | QS-JAN, ...         | QuarterBegin         |
    | BQS-JAN, ...        | BusinessQuarterBegin |
    | A-JAN, ...          | YearEnd              |
    | BA-JAN, ...         | BusinessYearEnd      |
    | AS-JAN, ...         | YearBegin            |
    | BAS-JAN, ...        | BusinessYearBegin    |
**** Users can define custon frequency classes
**** offsets can also be used with *datetime* or *Timestamp* objects
**** offset.rollforward/rollback
     #+BEGIN_SRC python
       ts.groupby(offset.rollforward).mean()
     #+END_SRC
     but *resample* is faster

*** Timezone
    internal library: *pytz*
**** tz_localize
**** tz_convert
*** Period
**** pandas.Period
**** pandas.PeriodIndex
*** Resample
    Aggregating higher frequency data to lower frequency is called downsampling,
    while converting lower frequency to higher frequency is called upsampling.
**** args
     #+CAPTION: Resample method arguments
     | Argument         | Description                                                                                                     |
     |------------------+-----------------------------------------------------------------------------------------------------------------|
     | freq             | String or DateOffset indicating desired resampled frequency, e.g. ‘M', ’5min', or Second(15)                    |
     | how='mean'       | Function name or array function producing aggregated value, for example 'ohlc' , np.max. Default 'mean'         |
     | axis=0           | Axis to resample on, default axis=0                                                                             |
     | fill_method=None | How to interpolate when upsampling, as in 'ffill' or 'bfill' . By default does no interpolation.                |
     | closed='right'   | In downsampling, which end of each interval is closed (inclusive). Default 'right'                              |
     | label='right'    | In downsampling, how to label the aggregated result, with the 'right' or 'left bin edge                         |
     | loffset=None     | Time adjustment to the bin labels, such as '-1s' / Second(-1) to shift the aggregate labels one second earlier  |
     | limit=None       | When forward or backward filling, the maximum number of periods to fill                                         |

*** useful functions
**** truncate
     slices a timeseries between two dates
**** normalize
     convert times to midnight

* wrangling
** Data Input/Output
*** Reading option categories
**** Indexing
     Can treat one or more columns as the returned DataFrame, and whether
     to get column names from the file, the user, or not at all.
**** Type inference and data conversion
     This includes the user-defined value conversions and custom list of
     missing value markers.
**** Datetime parsing
     Includes combining capability, including combining date and time information
     spread over multiple columns into a single column in the result.
**** Iterating
     Support for iterating over chunks of very large files.
**** Unclean data issues
     Skipping rows or a footer, comments, or other minor things like numeric data
     with thousands separated by commas.

*** Hints
   - *from_csv*: a convenience method simpler than read_csv
   - pickle related: *load*, *save*
** Concatenation
   - *pd.merge*, *merge* method
   - *join* method: performs a left join on the join keys
   - *pd.concat*
   - *combine_first*: patching missing data with arg object
*** concat args
    | Argument         | Description                                                                                                           |
    |------------------+-----------------------------------------------------------------------------------------------------------------------|
    | objs             | List or *dict* of pandas objects to be concatenated. The only required argument                                       |
    | axis             | Axis to concatenate along; defaults to 0                                                                              |
    | join             | One of 'inner', 'outer' , defaulting to 'outer'                                                                       |
    | join_axes        | Specific indexes to use for the other n-1 axes instead of performing union/intersection logic                         |
    | keys             | Values to associate with objects being concatenated, forming a hierarchical index along the concatenation axis        |
    | levels           | Specific indexes to use as hierarchical index level or levels if keys passed                                          |
    | names            | Names for created hierarchical levels if keys and / or levels passed                                                  |
    | verify_integrity | Check new axis in concatenated object for duplicates and raise exception if so. By default( False ) allows duplicates |
    | ignore_index     | Do not preserve indexes along concatenation axis , instead producing a new range(total_length) index                  |

** Reshaping and Pivoting
*** stack
    Pivots from the columns in the data to the rows.
    Stacking filters out missing data by default.
    #+BEGIN_SRC python
      data = DataFrame(np.arange(6).reshape((2, 3)), columns=['a', 'b', 'c'])
      data
      #=>
      #    a  b  c
      # 0  0  1  2
      # 1  3  4  5
      data.stack()
      #=>
      # 0  a    0
      #    b    1
      #    c    2
      # 1  a    3
      #    b    4
      #    c    5
      # dtype: int64
    #+END_SRC

*** unstack
    Pivots from the rows into the columns
    #+BEGIN_SRC python
      data.stack().unstack()
      #=>
      #    a  b  c
      # 0  0  1  2
      # 1  3  4  5

      # can specific level number or name
      data.stack().unstack(0)
      #=>
      #    0  1
      # a  0  3
      # b  1  4
      # c  2  5
    #+END_SRC

*** pivot
    *pivot* is a shortcut for creating a hierarchical index using *set_index* and reshaping with *unstack*
    #+BEGIN_SRC python
      quotes.head()
      #=>
      #                   Open        High         Low       Close    Volume  \
      # Date
      # 2010-01-04  626.951088  629.511067  624.241073  626.751061   3927000
      # 2010-01-05  627.181073  627.841071  621.541045  623.991055   6031900
      # 2010-01-06  625.861078  625.861078  606.361042  608.261023   7987100
      # 2010-01-07  609.401025  610.001045  592.651008  594.101005  12876600
      # 2010-01-08  592.000997  603.251034  589.110988  602.021036   9483900

      #              Adj Close symbol
      # Date
      # 2010-01-04  313.062468   GOOG
      # 2010-01-05  311.683844   GOOG
      # 2010-01-06  303.826685   GOOG
      # 2010-01-07  296.753749   GOOG
      # 2010-01-08  300.709808   GOOG
      quotes.pivot(columns='symbol', values='Close')
      #=>
      # symbol            AAPL        GOOG         IBM       MSFT
      # Date
      # 2010-01-04  214.009998  626.751061  132.449997  30.950001
      # 2010-01-05  214.379993  623.991055  130.850006  30.959999
      # 2010-01-06  210.969995  608.261023  130.000000  30.770000
      # 2010-01-07  210.580000  594.101005  129.550003  30.450001
      # 2010-01-08  211.980005  602.021036  130.850006  30.660000
    #+END_SRC

** Permutation(randomly reordering)
   #+BEGIN_SRC python
     df = DataFrame(np.arange(5 * 4).reshape(5, 4))
     df
     #=>
     #     0   1   2   3
     # 0   0   1   2   3
     # 1   4   5   6   7
     # 2   8   9  10  11
     # 3  12  13  14  15
     # 4  16  17  18  19
     sampler = np.random.permutation(5)
     sampler
     #=> array([1,0,2,3,4])
     df.take(sampler)
     #=>
     #     0   1   2   3
     # 1   4   5   6   7
     # 3  12  13  14  15
     # 4  16  17  18  19
     # 0   0   1   2   3
     # 2   8   9  10  11
   #+END_SRC
** String Manipulation
   df.str.XXX
*** Vectorized string methods
    cat, contains, count, endswith/startswith, findall, get,
    join, len, lower, upper, match, pad, center, repeat, replace,
    slice, split, strip/rstrip/lstrip
** Check Duplicates
   pandas.Index.is_unique, pandas.Series.is_unique
** Others
*** TODO Indicator/Dummy(for statistical model)
    *pd.get_dummies*
* plotting
** Basic
*** Figures and Subplots
    #+BEGIN_SRC python
      fig = plt.figure()
      ax1 = fig.add_subplot(2, 2, 1)
      # get a reference of active figure
      plt.gcf()

      # all in one subplots
      fig, axes = plt.subplots(2,3, figsize=(14, 8))
    #+END_SRC
*** subplots options
    | Argument  | Description                            |
    |-----------+----------------------------------------|
    | figsize   | Size of figure                         |
    | nrows     | Number of rows of subplots             |
    | ncols     | Number of columns of subplots          |
    | *sharex*  | All subplots use the same X-axis ticks |
    | *sharey*  | see above                              |
    | subpot_kw | creating dict of keywords              |
    | **fig_kw  | Additional keywords                    |
*** Adjusting Size
    subplots_adjust
    - args: left, right, bottom, top, wspace, hspace

*** global configuration
    plt.rc
    #+BEGIN_SRC python
      plt.rc('figure', figsize=(10, 10))
      font_options = {'family' : 'monospace',
                      'weight' : 'bold',
                      'size'
                      : 'small'}
      plt.rc('font', **font_options)
    #+END_SRC
** plot function
*** plotting range
    plt.xlim, plt.ylim, ax.set_xlim, ax.set_ylim

*** title, label, tick, ticklabel
    set_title, set_xlabel, set_xticks, set_xticklabels

*** legend
    #+BEGIN_SRC python
      fig = plt.figure()
      ax = fig.add_subplot(1, 1, 1)
      ax.plot(randn(1000).cumsum(), 'k', label='one')
      ax.legend(loc='best') #show the label
    #+END_SRC

*** Annotations
**** *text, arrows, annotate* functions
     #+BEGIN_SRC python
       ax.annotate(label, xy=(date, spx.asof(date) + 50),
                   xytext=(date, spx.asof(date) + 200),
                   arrowprops=dict(facecolor='black'),
                   horizontalalignment='left', verticalalignment='top')
     #+END_SRC
**** shapes
     matplotlib.patches
     #+BEGIN_SRC python
       fig = plt.figure()
       ax = fig.add_subplot(1, 1, 1)
       rect = plt.Rectangle((0.2, 0.75), 0.4, 0.15, color='k', alpha=0.3)
       circ = plt.Circle((0.7, 0.2), 0.15, color='b', alpha=0.3)
       ax.add_patch(rect)
       ax.add_patch(circ)
     #+END_SRC

** pandas Plotting
*** Line Plots
**** Series
     | Argument | Description                                                                             |
     |----------+-----------------------------------------------------------------------------------------|
     | label    | Label for plot legend                                                                   |
     | ax       | matplotlib subplot object to plot on. If nothing passed, uses active matplotlib subplot |
     | style    | Style string, like 'ko--' , to be passed to matplotlib                                  |
     | alpha    | The plot fill opacity (from 0 to 1)                                                     |
**** DataFrame
     | Argument       | Description                                      |
     |----------------+--------------------------------------------------|
     | kind           | Can be 'line', 'bar', 'barh', 'kde'              |
     | logy           | Use logarithmic scaling on the Y axis            |
     | use_index      | Use the object index for tick labels             |
     | rot            | Rotation of tick labels (0 through 360)          |
     | xticks         | Values to use for X axis ticks                   |
     | yticks         | Values to use for Y axis ticks                   |
     | xlim           | X axis limits (e.g. [0, 10] )                    |
     | ylim           | Y axis limits                                    |
     | grid           | Display axis grid (on by default)                |
     | subplots       | Plot each DataFrame column in a separate subplot |
     | sharex, sharey | If subplots=True , share the same Y/x axis       |
     | figsize        | Size of figure to create as tuple                |
     | title          | Plot title as string                             |
     | legend         | Add a subplot legend ( True by default)          |
     | sort_columns   | Plot columns in alphabetical order               |

*** Bar Plots
    - kind='bar': for vertical bars, 'barh' for horizontal bars
    - stacked=True: stacked bar plots
    - useful recipe: s.value_counts().plot(kind='bar')

*** Histogram & Density Plots
    - A kind of bar plot that gives a discretized display of value frequency
    #+BEGIN_SRC python
      comp1 = np.random.normal(0, 1, size=200) # N(0, 1)
      comp2 = np.random.normal(10, 2, size=200) # N(10, 4)
      values = Series(np.concatenate([comp1, comp2]))
      fig = plt.figure(figsize=(10, 5))
      values.hist(bins=100, alpha=0.3, color='k', normed=True)
      values.plot(kind='kde', style='k--')
    #+END_SRC
    #+ATTR_HTML: align="center"
    [[file:../resources/data/hist_kde_plot.png]]

*** Scatter Plots
    pairs plot or scatter plot matrix: *scatter_matrix*

** Saving Plots to File
   Figure.savefig args
   - fname, dpi, facecolor, edgecolor, format
   - bbox_inches: The portion of the figure to save

** add-ons
   - mplot3d
   - *basemap* /cartopy: projection and mapping(plotting 2D data on maps)
   - *seaborn* /holoviews/ggplot: higher-level plotting interfaces
   - axes_grid:  axes and axis helpers

* aggregation
** group by
   #+BEGIN_SRC python
     # series groupby
     df['data1'].groupby(df['key1'])
     df.groupby(df['key1'])['data1'] # syntactic sugar
     dict(list(df.groupby('key1')))

     # df groupby
     df.groupby(['key1', 'key2']) # options: as_index, axis

     # get group size
     df.groupby().size()

     # iterations
     for name, group in df.groupby('key1'):
         print name, group
   #+END_SRC
*** via dict
    #+BEGIN_SRC python
      # using mapping dict
      mapping = {'a': 'group1', 'b': 'group1', 'c': 'group2'}
      df.groupby(mapping, axis=1)
    #+END_SRC
*** via function
    Any function passed as a group key will be called once per
    index value, with the return values being used as the group names
    #+BEGIN_SRC python
      # using function
      df.groupby(len).sum()
    #+END_SRC
*** via mixing
    Mixing functions with arrays, dicts or Series is not a problem as
    everything gets converted to arrays internally
    #+BEGIN_SRC python
      key_list = ['one', 'one', 'two']
      df.groupby([len, key_list]).min()
    #+END_SRC

** groupby aggregation
   #+CAPTION: Optimized grouby methods
   | Name        | Description                                                  |
   |-------------+--------------------------------------------------------------|
   | count       | Number of non-NA values in the groupNumber of non            |
   | sum         | Sum of non-NA values                                         |
   | mean        | Mean of non-NA values                                        |
   | median      | Arithmetic median of non-NA values                           |
   | std, var    | Unbiased (n - 1 denominator) standard deviation and variance |
   | min, max    | Minimum and maximum of non-NA values                         |
   | prod        | Product of non-NA values                                     |
   | first, last | First and last non-NA values                                 |
*** *aggregate* / *agg* method
**** Series
     #+BEGIN_SRC python
       s.agg(['mean', 'std'])
       s.agg([('foo', 'mean'), ('bar', 'np.std')]) # foo bar will be the column name of result df
     #+END_SRC
**** DataFrame
     #+BEGIN_SRC python
       df.agg({'col1': 'mean', 'col2': 'std', 'col3': np.max})
       df.agg({'col1': ['mean', 'std']})
     #+END_SRC
*** apply
    apply function has args:
    #+BEGIN_SRC python
      df.groupby(['key1', 'key2']).apply(top, n=1)
    #+END_SRC
**** GroupBy method
     #+BEGIN_SRC python
       grouped.describe()
       # is just shortcut of
       f = lambda x: x.describe()
       grouped.apply(f)
     #+END_SRC
*** transform
    *transform* is a more specialized function having rigid requirements.
    *transform* applies a funtion to *each group*, then places the results
    in the appropriate locations. If each group produces a scalar value, it
    will be *propagated(broadcasted)*.
**** Standardizing data (zscore) within group
     #+BEGIN_SRC python
       key = lambda x: x.year
       zscore = lambda x: (x - x.mean()) / x.std()
       transformed = ts.groupby(key).transform(zscore)
     #+END_SRC

**** Filling NAs within groups with a value derived from each group
     #+BEGIN_SRC python
       f = lambda x: x.fillna(x.mean())
       transformed = grouped.transform(f)
     #+END_SRC
** cut & qcut
** fillna with group value
   #+BEGIN_SRC python
     grouped.apply(lambda g: g.fillna(g.mean()))

     fill_values = {'a': 5, 'b': 4}
     grouped.fillna(lambda g: g.fillna(fill_values[g.name]))
   #+END_SRC
** pivot_table
   *pivot_table* aggregates a table of data by one or more keys,
   arranging the data in a rectangle with some of the group keys along the rows and some
   along the columns. default aggfunc: mean
*** crosstab
    A cross-tabulation (or crosstab for short) is a special case of a pivot table
    that computes group frequencies.

* other tools
** dateutil
   parser.parse: parse datetime str to datetime object
** statsmodels
** scikit-learn
** visualization ecosystem
   - Chaco: 2-Dimensional Plotting, interactive visualization.
   - mayavi: a 3D graphics toolkit built on the open source C++ graphics library VTK
   - PyQwt
