#+TITLE: Statistic
#+KEYWORDS: math, statistic
#+OPTIONS: H:2 toc:2 num:3 ^:nil
#+OPTIONS: LaTeX:t
#+SETUPFILE: ../configOrg/level1.org
* Probability
** Probability Axioms
*** Nonnegativity
For every event A, $P(A) \ge 0$.
*** Additivity
$$P(A \cup B) = P(A)+P(B)$$
$$P(A_1 \cup A_2 \cup ...) = P(A_1) + P(A_2) + ...$$
*** Normalization
$$P(\Omega) = 1$$
** Probability Laws
- If $A\subset B$, then $P(A)\le P(B)$
- $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
- $P(A\cup B) \le P(A)+P(B)$
- $P(A\cup B\cup C) = P(A) + P(A^c\cap B) + P(A^c\cap B^c\cap C)$
- if $P(A \cap B)$ equals to 0, this stuation is called mutually exclusive
*** 独立事件的组合概率
if $A_1$ and $A_2$ are independent events.
$$P(A_1|A_2)=P(A_1)\times P(A_2)$$

** Binomial Theorem
$$(x+y)^n = \sum_{k=0}^{n} \dbinom{n}{k}x^{n-k}y^{k}$$

* Statistic
** central tendency
- mode
- median
  - *even* $\frac{x_\frac{n}{2} + x_{\frac{n}{2}+1}}{2}$
  - *odd* $x_\frac{n+1}{2}$

- mean
$$\mu = \frac{\sum_{i=1}^{N}x_i}{N}$$
or
$$\mu = \sum_{i=1}^{N}p_i\cdot x_i$$

** variability
- range

  cut off the upper 25% and lower 25% tails of the distribution

- IQR(Interquartile Range)

  $$Q_3 - Q_1$$
  $Q_1$ is the midean of the first half

  #+ATTR_HTML: align="left"
  file:../resources/math/IQR.png

- Outlier

  whiskers = 1.5
  $$< Q_1 - whiskers\cdot(IQR)$$
  $$> Q_3 + whiskers\cdot(IQR)$$

- MAD

  mean absolute deviation

- Variance

  $$\sigma^2 = \frac{\sum_{i=1}^N(x_i-\mu)^2}{N}$$
  $$\sigma^2 = \frac{\sum_{i=1}^Nx_i^2}{N} - \mu^2$$
  Bessel's Correction: a better estimate of population
  $$\sigma^2 = \frac{\sum_{i=1}^N(x_i-\mu)^2}{N-1}$$

- SD
  #+BEGIN_VERSE
  standard deviation $\sigma$
  approximately 68% lie within one SD of the mean
  approximately 95% lie within two SD of the mean
  #+END_VERSE

  calculate numbers of SD
  $$z=\frac{x-\mu}{\sigma}$$
* Sampling Distribution
** Central limit theorem
1. The distribution of sample means is approximately normal
2. The standard deviation of the sample(standard error) means $\approx\frac{\sigma}{\sqrt{n}}$
3. The mean of the sample means $\approx\mu$
** Confidence Interval
- Y% confidence interval:
  #+BEGIN_VERSE
  $$(\bar{x}-z\frac{\sigma}{\sqrt{n}}, \bar{x}+z\frac{\sigma}{\sqrt{n}})$$
  $\pm{z}$ are the critical values of Y% confidence interval
  #+END_VERSE
- Margin of error $z\frac{\sigma}{\sqrt{n}}$
** Terms
| z-score               | number of standard deviation away from $\mu$ |
| sampling distribution | distribution of sample means                 |
| standard error        | the SD of the sampling distribution          |
* Hypothesis testing
- $\alpha$ levels

  #+BEGIN_VERSE
  Levels of likelihood: 5%, 1%, 0.1%.
  If the probability of getting a particular sample mean is less than 5%,
  it is unlikely to occur.
  #+END_VERSE

- critical region: the aera with the probability is less than particular $\alpha$ level
- critical value: the z-score of the $\alpha$ level

** null hypothesis $H_0$
$$\mu\approx\mu_I$$
- type 1 error
  #+BEGIN_VERSE
  Reject $H_0$, but in the real world $H_0$ is true.
  We think our hypothesis is correct, but it is wrong.
  #+END_VERSE
- type 2 error
  #+BEGIN_VERSE
  Retain $H_0$, but in the real world $H_0$ is false.
  We think our hypothesis is wrong, but it is true.
  #+END_VERSE

** alternative hypothesis $H_A$
$$\mu\neq\mu_I, \mu<\mu_I, \mu>\mu_I$$
* T-Tests
** DF(degree of freedom)
** t-score(one sample)
$$t=\frac{\bar{x}-\mu_0}{S/\sqrt{n}}$$
** Cohen's d
#+BEGIN_VERSE
standardized mean difference that measures the distance
between means in standardized units.
#+END_VERSE
$$Cohen's d = \frac{\bar{x}-\mu_0}{S}$$
** Dependent t-test
$$t=\frac{\bar{x}_D-\mu_D}{S_D\sqrt{n}}$$
$$CI=M_D\pm t_{critical}\cdot\frac{S_D}{\sqrt{n}}$$
*** Within-Subject designs
- Two conditions
- Pre-test, post-test
- Growth over time(longitudinal study)
*** Effect size
- difference measures: mean, standardized
  #+BEGIN_VERSE
  cohen's == standardized mean difference
  #+END_VERSE
- correlation measures
  #+BEGIN_VERSE
  $r^2$ % of variation in one variable that is related to
  ('explained by') another variable.
  #+END_VERSE
*** Statistical significance
Statistical significance means:
- rejected the null
- results are not likely due to chance(sampling error)

** Meaningfulness of Results
1. What was measured?
2. Effect size
3. Can we rule out random chance?
4. Can we rule out alternative explanations?(lurking variables)
** Correlation $r_2$
$$r^2 = \frac{t^2}{t^2+DF}$$
* Correlation
** $r_2$ - coefficient of determination
