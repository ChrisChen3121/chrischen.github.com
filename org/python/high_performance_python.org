#+TITLE: High Performance Python
#+KEYWORDS: python, performance
#+OPTIONS: H:3 toc:2 num:3 ^:nil
#+LANGUAGE: en-US
#+AUTHOR: ChrisChen
#+EMAIL: ChrisChen3121@gmail.com
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
* Hardware Resources
** Computing Unit
   The main properties of interest in a computing unit are the number of operations
   it can do in one cycle and the number of cycles it can do in one second. The first
   value is measured by its instructions per cycle(IPC), while the latter value is
   measured by its clock speed.
   - *SIMD*: Single instruction, multiple data. Efficient with high IPC. (CPU vectorization instruction)
   - *Hyperthreading* presents a virtual second CPU to the host OS, and clever hardware logic tries
   to interleave two threads of instructions into the execution units on a single CPU. When successful,
   gains of up to 30% over a single thread can be achieved.

** Memory Unit
   When trying to optimize the memory patterns of a program, we are simply optimizing
   which data is placed where, how it is laid out (in order to increase the number of
   sequential reads), and how many times it is moved among the various locations.

** Communications Layers
   - The /frontside/ bus is the connection between the RAM and the L1/L2 cache
   - Two main properties of a bus:
     - how much data can be moved in one transfer (bus width)
     - how many transfers the bus can do per second (bus frequency).

** GPU
   - Drawbacks: Communicates through the PCI bus, which is much slower than the frontside bus

** Performance Issues of Python
   - Memory Fragmentation: due to garbage-collected
   - Dynamic Types: Using Cython to mitigate this problem
   - GIL: Using Cython or foreign functions

* Profiling
** Tools
*** ~timefn~ decorator
   #+BEGIN_SRC python
     def timefn(fn):
	 @wraps(fn)
	 def measure_time(*args, **kwargs):
	     t1 = time.time()
	     result = fn(*args, **kwargs)
	     t2 = time.time()
	     print(f"@timefn: {fn.__name__} took {t2 - t1} seconds")
	     return result
	 return measure_time
   #+END_SRC

*** bulit-in ~timeit~ module
   - [[https://docs.python.org/3/library/timeit.html][Documentation]]
   - The ~timeit~ module temporarily disables the garbage collector.
   - More useful approach: IPython magic ~%timeit~

*** CProfile
   #+BEGIN_SRC sh
     python -m cProfile -s cumulative test.py
     python -m cProfile -o profile.stats test.py
   #+END_SRC
   #+BEGIN_SRC python
     import pstats
     p = pstats.Stats("profile.stats")
     p.sort_stats("cumulative")
     p.print_stats()
     p.print_callers()
     p.print_callees()
   #+END_SRC
   - ~snakeviz~ for visualization

*** ~line_profiler~
   1. ~pip install ~line_profiler~~
   1. Use ~@profile~ to mark the chosen function
   1. ~kernprof -l -v test.py~
*** ~memory_profiler~
   1. ~pip install psutil~ (recommended)
   1. ~pip install memory_profiler~
   1. Use ~@profile~ to mark the chosen function
   1. ~python -m memory_profiler test.py~ or ~mprof run test.py~

   Other Hints:
   - using ~with profile.timestamp("scope1")~ to add label
   - ~memory_profiler~ offers an interesting aid to debugging a large process via the ~--pdb-mmem=XXX~ flag

*** ipython magic ~%memit~

*** No-op @profile
   Add it to the start of our module while unit testing
   #+BEGIN_SRC python
     if 'line_profiler' not in dir() and 'profile' not in dir():
	 def profile(func):
	     return func
   #+END_SRC

*** Introspecting an Existing Process with ~PySpy~
   - ~pip install py-spy~
   - ~sudo py-spy top --pid 2046~: top-like view.
   - ~py-spy record -o profile.svg python test.py~

*** Bytecode: ~dis~ module
    ~dis.dis(func)~
*** For Web Servers
    - ~dowser~
    - ~dozer~

** Practical Points
   - Disable Turbo Boost in the BIOS.
   - Disable the operating system’s ability to override the SpeedStep(in BIOS).
   - Use only AC power (never battery power).
   - Disable background tools like backups and Dropbox while running experiments.
   - Run the experiments many times to obtain a stable measurement.
   - Possibly drop to run level 1 (Unix) so that no other tasks are running.
   - Reboot and rerun the experiments to double-confirm the results.
   - Unit testing a complicated section of code that generates a large numerical output may be
   difficult. Do not be afraid to output a text file of results to run through ~diff~ or to use
   a pickled object.

* Lists and Tuples
  - Python array stores data in buckets by reference, opposed to numpy arrays.

** Lists
   - lists also store how large they are, so of the six allocated blocks, only five are usable.
   - ~bisect~ gives easy methods to add elements into a list while maintaining its sorting

*** Bulit-in Tim Sort
   Python lists have a built-in sorting algorithm that uses *Tim sort*.
   O(n) in the best case, O(n log n) in the worst case. It hybridizes
   insertion and merge sort algorithms.

* Lists and tuples
** Sort algorithm
*** Tim sort
built-in sort algorithm
(it hybridizes insertion and merge sort algorithms).

*** bisect
    *bisect* provides support for maintaining a list in
    sorted order without having to sort the list after each insertion.
    #+BEGIN_SRC python
      import bisect
      alist=[]
      bisect.insort(alist, 5)
      bisect.insort(alist, 3)
      bisect.insort(alist, 20)
      bisect.insort(alist, 17)
      print alist
      #=> [3, 5, 17, 20]
    #+END_SRC

** list vs. tuple
*** list
dynamic arrays, mutable and allow for resizing.

**** resizing
     The growth pattern is:
     | new size      | 0 | 1 | 5 |  9 | 17 | 26 | 36 | 47 | ... |
     | new allocated | 0 | 4 | 8 | 16 | 25 | 35 | 46 | 58 | ... |
  #+BEGIN_SRC c
    new_allocated = (newsize >> 3) + (newsize < 9 ? 3 : 6);
    new_allocated += newsize;
  #+END_SRC

**** dereference
     List objects (for background, see Chapter 3) have an overhead for each dereference, as
     the objects they reference can occur anywhere in memory.

*** tuple
    static arrays, immutable
- instantiating a list can be 5.1x slower than instantiating a tuple
- tuple is a hashable type

* set & dict
** hashable key
   The type should implements both the __hash__ magic function and either __eq__ or __cmp__ .
*** probing function
    #+BEGIN_SRC python
      # pseudocode
      # mask is always equal to bin(hashtable_size - 1)
      def index_sequence(key, mask=0b111, PERTURB_SHIFT=5):
	  perturb = hash(key)
	  i = perturb & mask
	  yield i
	  while True:
	      i = ((i << 2) + i + perturb + 1)
	      perturb >>= PERTURB_SHIFT
	      yield i & mask
    #+END_SRC
*** User-defined classes
    User-defined classes have default hash and comparison functions.
    The default __hash__ function simply returns the object’s placement
    in memory as given by the built-in id function. Similarly,
    the __cmp__ operator compares the numerical value of the object’s
    placement in memory.

*** entropy
    “how well distributed my hash function is” is called the *entropy*
    of the hash function:
    $$S = - \sum_i p(i)\cdot\log(p(i))$$

    where p(i) is the probability that the hash function gives hash i.

    knowing up front what range of values will be used and how large
    the dictionary will be helps in making a good selection.

** resizing

**** The growth pattern is:

     8, 32, 128, 512, 2048, 8192, 32768, 131072, 262144, ...
     the number of bucket increases by 4x until we reach 50,000
     elements, after which the size is increased by 2x.

     resizing requires recomputing indices
** extra
*** Namespace lookups
  #+BEGIN_SRC python
    import math
    from math import sin
    def test1(x):
	"""
	>>> %timeit test1(123456)
	1000000 loops, best of 3: 381 ns per loop
	"""
	return math.sin(x)

    def test2(x):
	"""
	>>> %timeit test2(123456)
	1000000 loops, best of 3: 311 ns per loop
	"""
	return sin(x)

    def test3(x, sin=math.sin):
	"""
	>>> %timeit test3(123456)
	1000000 loops, best of 3: 306 ns per loop
	"""
	return sin(x)
  #+END_SRC
  #+BEGIN_SRC python
    dis.dis(test1)
    # 0 LOAD_GLOBAL      0 (math)  # Dictionary lookup
    # 3 LOAD_ATTR        1 (sin)   # Dictionary lookup
    # 6 LOAD_FAST        0 (x)     # Local lookup
    # 9 CALL_FUNCTION    1
    # 12 RETURN_VALUE

    dis.dis(test2)
    # 0 LOAD_GLOBAL      0 (sin)   # Dictionary lookup
    # 3 LOAD_FAST        0 (x)     # Local lookup
    # 6 CALL_FUNCTION    1
    # 9 RETURN_VALUE

    dis.dis(test3)
    # 0 LOAD_FAST        1 (sin)   # Local lookup
    # 3 LOAD_FAST        0 (x)     # Local lookup
    # 6 CALL_FUNCTION    1
    # 9 RETURN_VALUE
  #+END_SRC
