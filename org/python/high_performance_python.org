#+TITLE: High Performance Python
#+KEYWORDS: python, performance
#+OPTIONS: H:3 toc:2 num:3 ^:nil
#+LANGUAGE: en-US
#+AUTHOR: ChrisChen
#+EMAIL: ChrisChen3121@gmail.com
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
* Hardware Resources
** Computing Unit
   The main properties of interest in a computing unit are the number of operations
   it can do in one cycle and the number of cycles it can do in one second. The first
   value is measured by its instructions per cycle(IPC), while the latter value is
   measured by its clock speed.
   - *SIMD*: Single instruction, multiple data. Efficient with high IPC. (CPU vectorization instruction)
   - *Hyperthreading* presents a virtual second CPU to the host OS, and clever hardware logic tries
   to interleave two threads of instructions into the execution units on a single CPU. When successful,
   gains of up to 30% over a single thread can be achieved.

** Memory Unit
   When trying to optimize the memory patterns of a program, we are simply optimizing
   which data is placed where, how it is laid out (in order to increase the number of
   sequential reads), and how many times it is moved among the various locations.

** Communications Layers
   - The /frontside/ bus is the connection between the RAM and the L1/L2 cache
   - Two main properties of a bus:
     - how much data can be moved in one transfer (bus width)
     - how many transfers the bus can do per second (bus frequency).

** GPU
   - Drawbacks: Communicates through the PCI bus, which is much slower than the frontside bus

** Performance Issues of Python
   - Memory Fragmentation: due to garbage-collected
   - Dynamic Types: Using Cython to mitigate this problem
   - GIL: Using Cython or foreign functions

* Profiling
** Tools
*** ~/usr/bin/time~
    - Using ~--verbose~ flag to get more details.
    - Most useful indicator is ~Major (requiring I/O) page faults~, as it indicates cache misses.
*** ~timefn~ decorator
   #+BEGIN_SRC python
     def timefn(fn):
	 @wraps(fn)
	 def measure_time(*args, **kwargs):
	     t1 = time.time()
	     result = fn(*args, **kwargs)
	     t2 = time.time()
	     print(f"@timefn: {fn.__name__} took {t2 - t1} seconds")
	     return result
	 return measure_time
   #+END_SRC

*** bulit-in ~timeit~ module
   - [[https://docs.python.org/3/library/timeit.html][Documentation]]
   - The ~timeit~ module temporarily disables the garbage collector.
   - More useful approach: IPython magic ~%timeit~

*** CProfile
   #+BEGIN_SRC sh
     python -m cProfile -s cumulative test.py
     python -m cProfile -o profile.stats test.py
   #+END_SRC
   #+BEGIN_SRC python
     import pstats
     p = pstats.Stats("profile.stats")
     p.sort_stats("cumulative")
     p.print_stats()
     p.print_callers()
     p.print_callees()
   #+END_SRC
   - ~snakeviz~ for visualization

*** ~line_profiler~
   1. ~pip install ~line_profiler~~
   1. Use ~@profile~ to mark the chosen function
   1. ~kernprof -l -v test.py~
   1. See report: ~python -m line_profiler test.py.lprof~

*** ~memory_profiler~
   1. ~pip install psutil~ (recommended)
   1. ~pip install memory_profiler~
   1. Use ~@profile~ to mark the chosen function
   1. ~python -m memory_profiler test.py~ or ~mprof run test.py~

   Other Hints:
   - using ~with profile.timestamp("scope1")~ to add label
   - ~memory_profiler~ offers an interesting aid to debugging a large process via the ~--pdb-mmem=XXX~ flag

*** ipython magic ~%memit~

*** No-op @profile
   Add it to the start of our module while unit testing
   #+BEGIN_SRC python
     if 'line_profiler' not in dir() and 'profile' not in dir():
	 def profile(func):
	     return func
   #+END_SRC

*** Introspecting an Existing Process with ~PySpy~
   - ~pip install py-spy~
   - ~sudo py-spy top --pid 2046~: top-like view.
   - ~py-spy record -o profile.svg python test.py~

*** Bytecode: ~dis~ module
    ~dis.dis(func)~
*** For Web Servers
    - ~dowser~
    - ~dozer~


** Practical Points
   - Disable Turbo Boost in the BIOS.
   - Disable the operating system’s ability to override the SpeedStep(in BIOS).
   - Use only AC power (never battery power).
   - Disable background tools like backups and Dropbox while running experiments.
   - Run the experiments many times to obtain a stable measurement.
   - Possibly drop to run level 1 (Unix) so that no other tasks are running.
   - Reboot and rerun the experiments to double-confirm the results.
   - Unit testing a complicated section of code that generates a large numerical output may be
   difficult. Do not be afraid to output a text file of results to run through ~diff~ or to use
   a pickled object.

* Lists and Tuples
  - Python array stores data in buckets by reference, opposed to numpy arrays.

** Lists
   - lists also store how large they are, so of the six allocated blocks, only five are usable.
   - ~bisect~ gives easy methods to add elements into a list while maintaining its sorting
   - List pre-allocation equation in Python 3.7: ~M = (N >> 3) + (3 if N < 9 else 6)~

*** Bulit-in Tim Sort
   Python lists have a built-in sorting algorithm that uses *Tim sort*.
   O(n) in the best case, ~O(n log n)~ in the worst case. It hybridizes
   insertion and merge sort algorithms.

** Tuples
   Python process will have some extra memory overhead for resource caching.
   For tuples of sizes 1–20, however, when they are no longer in use, the space isn't
   immediately given back to the system, which reduced system calls for memory allocation.
   #+BEGIN_SRC text
     In [1]: %timeit l = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
     62 ns ± 0.714 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)

     In [2]: %timeit t = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)
     9.41 ns ± 0.113 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)
   #+END_SRC

* Dictionaries and Sets
** Hashable Type
   - should implement ~__hash__~, ~__eq__~, ~__cmp_-~
   - User-defined classes have default hash and comparison functions using the object's placement in memory.(given by ~id~ function)

** Key to Array Index
   1. *hashing*: turn key into an integer number
   1. *masking*: fits the allocated number of buckets
   1. Using *probing* to find a new place if collision happens
   #+BEGIN_SRC python
     # pseudocode of finding index
     def index_sequence(key, mask=0b111, PERTURB_SHIFT=5):
	 perturb = hash(key)  # hashing
	 i = perturb & mask  # masking
	 yield i
	 # probing
	 while True:
	     perturb >>= PERTURB_SHIFT  # use high-order bits
	     i = (i * 5 + perturb + 1) & mask  # simple linear function and masking again
	     yield i
   #+END_SRC

*** Finding a Element
    If we hit an empty bucket, we can conclude that the data does not exist in the table.

*** Deleting a Element
    We will write a special value that signifies that the bucket is empty, but there still
    may be values after it to consider when resolving a hash collision. These empty slots can
    be written to in the future and are removed when the hash table is resized.

*** Entropy of a Hash Function
    $$S = -\sum_i p(i)\cdot\log(p(i))$$
    - $p(i)$ is the probability that the hash function gives hash i
    - It is maximized when every hash value has equal probability of being chosen
    #+BEGIN_SRC python
      import math
      p1 = [0.25, 0.25, 0.25, 0.25]
      -sum(i * math.log(i) for i in p1)  # => 1.3862943611198906

      p2 = [0.1, 0.3, 0.5, 0.1]
      -sum(i * math.log(i) for i in p2)  # => 1.1682824501765625
    #+END_SRC
    - Knowing up front *what range of values will be used* and *how large the dictionary will be* helps in making a good selection

** Dictionary
   - Optimization: Python first appends the key/value data into a standard array and
   then stores only the index into this array in the hash table. The array also helps
   keep the insertion order of items.
   - How well distributed the data is throughout the hash table is called the *load factor* and is related to the *entropy* of the hash function
   - By default, the smallest size of a dictionary or set is 8, and it will resize by 3x if the dictionary is more than two-thirds full. (possible sizes: 8->18->39->81->165->...)


** Namespace Management
   - *Namespace Management* heavily uses dictionaries to do its lookups.

   The steps to look for a variable/function/module

   1. Searching ~locals()~: which has entries for all local variables, and this is the only part of the chain that doesn't require a dictionary lookup
   2. Searching ~globals()~
   3. Searching ~__builtin__~ objects: ~__builtin__~ is technically a module object
   #+BEGIN_SRC python
     import math


     def test1(x):
	 """
	 >>> %timeit test1(123456)
	 94 µs ± 387 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)

	 18 LOAD_GLOBAL              1 (math)
	 20 LOAD_METHOD              2 (sin)
	 22 LOAD_FAST                0 (x)
	 24 CALL_METHOD              1

	 """
	 res = 1
	 for _ in range(1000):
	     res += math.sin(x)
	 return res


     def test2(x):
	 """
	 >>> %timeit test2(123456)
	 72.5 µs ± 2.66 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)

	 22 LOAD_FAST                2 (res)
	 24 LOAD_FAST                1 (sin)
	 26 LOAD_FAST                0 (x)
	 28 CALL_FUNCTION            1

	 """
	 sin = math.sin
	 res = 1
	 for _ in range(1000):
	     res += sin(x)
	 return res
   #+END_SRC
