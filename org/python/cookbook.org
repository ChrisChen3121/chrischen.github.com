#+TITLE: Python Cookbook
#+KEYWORDS: python, cookbook
#+OPTIONS: H:3 toc:1 num:3 ^:nil
#+LANGUAGE: en-US
#+AUTHOR: chrischen
#+EMAIL: chrischen3121@gmail.com
#+SETUPFILE: ../../org-templates/level-1.org
#+STARTUP: inlineimages
* Data Structures and Algorithms
** Unpacking from Iterables
   #+BEGIN_SRC python
     x, *middle, y = [1, 2, 3, 4, 5] # middle can be replaced by placeholder '_'
     # x => 1
     # y => 5

     data = ['ACME', 50, 91.1, (2012, 12, 21)]
     name, shares, price, (year, mon, day) = data
   #+END_SRC

** Keeping the Last N Items
   #+BEGIN_SRC python
     from collections import deque
     d=deque(maxlen=N)
   #+END_SRC

** Finding the Largest N Items
   #+BEGIN_SRC python
     import heapq
     heapq.nlargest(N, items)
     heapq.nsmallest(N, items)
     # heapq.nlargest(N, data, key=lambda function)
   #+END_SRC
   Underneath the covers, they work by first converting the data into a list
   where items are ordered as a heap.
   #+BEGIN_SRC python
     nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]
     heapq.heapify(nums) # inplace function
     # nums => [-4, 2, 1, 23, 7, 2, 18, 23, 42, 37, 8] heap[0] is the smallest
   #+END_SRC

** PriorityQueue Implemention
   #+BEGIN_SRC python
     import heapq

     class PriorityQueue:
         def __init__(self):
             self._queue = []
             self._index = 0 # use index to properly order items with the same priority level

         def push(self, item, priority):
             heapq.heappush(self._queue, (-priority, self._index, item))
             self._index += 1

         def pop(self):
             return heapq.heappop(self._queue)[-1]
   #+END_SRC

** defaultdict
   #+BEGIN_SRC python
     from collections import defaultdict
     d = defaultdict(list)
     d['a']
     #=> []
   #+END_SRC
   *defaultdict* will automatically create dictionary entries for keys accessed later on, alternative:
   #+BEGIN_SRC python
     d.setdefault('a', []).append(1)
   #+END_SRC
*** alternative
    #+BEGIN_SRC python
      d = {}
      # A regular dictionary
      d.setdefault('a', []).append(1)
    #+END_SRC

** OrderedDict
   An OrderedDict internally maintains a doubly linked list that orders the keys according to insertion order.

** sortedcontainers
   SortedList, SortedDict, SortedSet

** Calculating with Dictionaries
   #+BEGIN_SRC python
     prices = {
         'ACME': 45.23,
         'AAPL': 612.78,
         'IBM': 205.55,
         'HPQ': 37.20,
         'FB': 10.75
     }
     min_price = min(zip(prices.values(), prices.keys())) # zip to ((value, key)) generator

     min(prices, key=lambda k: prices[k]) # Returns 'FB'
     min_value = prices[min(prices, key=lambda k: prices[k])]
   #+END_SRC

** keys-view
   #+BEGIN_SRC python
     a.keys() & b.keys()
     a.keys() - {'z', 'w'} # {'z', 'w'} is a set
   #+END_SRC

** Naming a Slice
   #+BEGIN_SRC python
     a = [1,2,3,4,5]
     b = slice(1,2)

     a[b] #=> [2] slower than a[1]
   #+END_SRC

** Counting
   #+BEGIN_SRC python
     from collections import Counter
     word_counts1 = Counter(words1)
     word_counts2 = Counter(words2)
     word_counts1 + word_counts2
   #+END_SRC

** Sorting a List of Dictionaries
   #+BEGIN_SRC python
     from operator import itemgetter
     rows_by_fname = sorted(rows, key=itemgetter('fname'))
     rows_by_lfname = sorted(rows, key=itemgetter('lname','fname'))

     g = itemgetter(2, 5, 3) # the call g(r) returns (r[2], r[5], r[3])
   #+END_SRC

** Sorting Objects Without Native Comparison
   #+BEGIN_SRC python
     sorted(users, key=lambda u: u.user_id)
     from operator import attrgetter
     sorted(users, key=attrgetter('user_id'))
     by_name = sorted(users, key=attrgetter('last_name', 'first_name'))
   #+END_SRC

** groupby
   Since =groupby()= only examines consecutive items, should sort the groupby key first.
   #+BEGIN_SRC python
     from itertools import groupby
     rows.sort(key=itemgetter('date'))
     for date, items in groupby(rows, key=itemgetter('date')):
         pass
     # alternative if memory is no concern, and faster than sort+groupby
     rows_by_date = defaultdict(list)
     for row in rows:
         rows_by_date[row['date']].append(row)
   #+END_SRC
** itertools.compress
   Like boolean index in pandas. Takes an iterable and an accompanying Boolean selector sequence as input.
   =list(compress(data, mask))=

** namedtuple & namedlist
   optional or missing fields
   #+BEGIN_SRC python
     Stock = namedtuple('Stock', ['name', 'shares', 'price', 'date', 'time'])
     Stock.__new__.__defaults__ = ('', 0, 0, None, None)
     # or
     stock_prototype = Stock('', 0, 0.0, None, None)

     def dict_to_stock(s):
         return stock_prototype._replace(**s)
   #+END_SRC
*** useful method
    - ~_make~: Make a new Stock object from a sequence or iterable
    - ~_replace~
    - ~_fields~
    - ~_asdict~

** sum, min,...
   #+BEGIN_SRC python
     s = sum((x * x for x in nums))
     s = sum(x * x for x in nums) # same as above

     # Original: Returns 20
     min_shares = min(s['shares'] for s in portfolio)
     # Alternative: Returns {'name': 'AOL', 'shares': 20}
     min_shares = min(portfolio, key=lambda s: s['shares'])
   #+END_SRC

** ChainMap
   A ChainMap takes multiple mappings and makes them logically appear as one. If there are duplicate keys,
   the values from the first mapping get used.
   #+BEGIN_SRC python
     from collections import ChainMap
     c = ChainMap(a,b)
     # alternative
     c = b
     c.update(a)
   #+END_SRC
   - but ChainMap keep the reference of a&b

*** store scoped values
   A ChainMap is particularly useful when working with scoped values such as variables in
   a programming language (i.e., globals, locals, etc.)
   #+BEGIN_SRC python
     values = ChainMap()
     values['x'] = 1
     values = values.new_child()
     values['x'] = 2
     values['x'] #=> 2
     values = values.parents
     values['x'] #=> 1
   #+END_SRC
* String Manipulation
** modules
   - *fnmatch*: Filename matching with shell patterns.
   - *glob*: Filename globbing utility.

** re
*** find
    - =match()=
    - =findall()=
    - =finditer()=
    - =scaner()=

*** replace
    - =sub=

*** regex
    - named capture group: =r'?P<TOKENNAME>[a-zA-Z]+'=
    - noncapture

*** tokenize
**** Problem
     You have a string that you want to parse left to right into a stream of tokens.
**** Usage
    #+BEGIN_SRC python
      from collections import namedtuple
      Token = namedtuple('Token', ['type', 'value'])


      def generate_tokens(pat, text):
          scanner = pat.scanner(text)
          for m in iter(scanner.match, None):
              yield Token(m.lastgroup, m.group())


      # Example use
      for tok in generate_tokens(master_pat, 'foo = 42'):
          print(tok)

      # Produces output
      # Token(type='NAME', value='foo')
      # Token(type='WS', value=' ')
      # Token(type='EQ', value='=')
      # Token(type='WS', value=' ')
      # Token(type='NUM', value='42')
    #+END_SRC
    =scanner()= method of pattern objects. This method creates a scanner object in which repeated calls to match() step through the
    supplied text one match at a time

*** syntax parser
    - PyParsing
    - PLY
    - Recipe: 2.19

** format
*** align
    #+BEGIN_SRC python
      format('right', '>20')
      # '               right'
      format('right', '=>20')
      # '===============right'
    #+END_SRC

*** safesub
    #+BEGIN_SRC python
      class safesub(dict):
          def __missing__(self, key):
              return '{' + key + '}'

      name = 'ABC'
      n = 5
      s = '{name} has {n} messages.'
      s.format_map(safesub(vars()))
      # 'ABC has 5 messages.'
    #+END_SRC
**** frame hack
     #+BEGIN_SRC python
       def sub(text):
           return text.format_map(safesub(sys._getframe(1).f_locals))
     #+END_SRC

*** textwrap
    The textwrap module is a straightforward way to clean up text for printing.
    =textwrap.fill()= reformat text for output.

** join
   - ='abc' + ',' + 'def'=
   - ='abc' ',' 'def'=
   - =','.join(('abc', 'def'))=
   - ='{},{}'.format('abc', 'def')=
   - print('abc', 'def', sep=',')

** Combining I/O Write Operation
   #+BEGIN_SRC python
     def combine(source, maxsize):
         parts = []
         size = 0
         for part in source:
             parts.append(part)
             size += len(part)
             if size > maxsize:
                 yield ''.join(parts)
                 parts = []
                 size = 0
         yield ''.join(parts)

     for part in combine(sample(), 32768):
         f.write(part)
   #+END_SRC
   - Example: write to socket send buffer

** escape
   - =html.escape=
   - =xml.escape=

** Tokenizing Text
   #+BEGIN_SRC python
     import re
     from collections import namedtuple

     NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'
     NUM = r'(?P<NUM>\d+)'
     PLUS = r'(?P<PLUS>\+)'
     TIMES = r'(?P<TIMES>\*)'
     EQ = r'(?P<EQ>=)'
     WS = r'(?P<WS>\s+)'

     master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))

     Token = namedtuple('Token', ['type', 'value'])


     def generate_tokens(pat, text):
         # scanner method creates a scanner object in which repeated calls to match()
         # step through the supplied text one match at a time
         scanner = pat.scanner(text)
         for m in iter(scanner.match, None):
             yield Token(m.lastgroup, m.group())


     tokens = (tok for tok in generate_tokens(master_pat, 'foo = 42')
               if tok.type != 'WS')
     for tok in tokens:
         print(tok)

     # Produces output
     # Token(type='NAME', value='foo')
     # Token(type='EQ', value='=')
     # Token(type='NUM', value='42')
   #+END_SRC

* Numbers
** round
   #+BEGIN_SRC python
     round(1.29, 1)
     # => 1.3
     round(1245, -1)
     # => 1240
     round(1275, -1)
     # => 1280
   #+END_SRC

** Decimal
   #+BEGIN_SRC python
     from decimal import Decimal, localcontext
     a = Decimal('6.32')
     b = Decimal('2.41')

     with localcontext() as ctx:
         ctx.prec = 5
         print(a/b) # 2.6224
   #+END_SRC

** Formatting
   #+BEGIN_SRC python
     x = 1234.56789
     format(x, '0.2f')
     # => '1234.57'   # round
     format(x, '>10.1f')
     # => '    1234.6'
     format(x, '0,.1f')
     # => '1,234.6

     x = 1234
     bin(x)  # others: oct, hex
     # => '0b10011010010'
     format(x, 'b')  # others: o, x
     # => '0011010010'
     int('10011010010', 2)
     # => 1234
   #+END_SRC

** Bin, Oct, Hex Int
   #+BEGIN_SRC python
     x = -1234
     format(x, 'b')
     #=> '-10011010010'
     format(x, 'x')
     #=> '-4d2'
     format(2**32 + x, 'b')
     #=> '11111111111111111111101100101110'
     format(2**32 + x, 'x')
     #=> 'fffffb2e'
     int('4d2', 16)
     #=> 1234
     int('10011010010', 2)
     #=> 1234
   #+END_SRC

** Bytes2Int
   #+BEGIN_SRC python
     data = b'\x00\x124V\x00x\x90\xab\x00\xcd\xef\x01\x00#\x004'
     x = int.from_bytes(data, 'little')  # or 'big

     x = 94522842520747284487117727783387188
     x.to_bytes(16, 'little')
   #+END_SRC
   useful in cryptography or networking domains
   - ~struct~ module
   - ~int.bit_length()~

** Complex Math
   #+BEGIN_SRC python
     a = complex(2, 4)
     b = 3 - 5j
     a.conjugate()
     #=> (2-4j)
     abs(a)
     #=> 4.47213595499958
     a * b
     #=> (26+2j)

     import cmath
     cmath.sin(a)
     #=> (24.83130584894638-11.356612711218174j)

     import numpy as np
     a = np.array([2 + 3j, 4 + 5j, 6 - 7j, 8 + 9j])
     np.sin(a)
   #+END_SRC

** random
   - =random.choice=
   - =random.sample=
   - =random.shuffle=
   - =random.randint=
   - =random.random=: 0 to 1
   - =random.getrandbits=
*** seed
    #+BEGIN_SRC python
      random.seed()  # Seed based on system time or os.urandom()
      random.seed(12345)  # Seed based on integer given
      random.seed(b'bytedata')  # Seed based on byte data
    #+END_SRC

*** distribution
    - =random.uniform=
    - =random.gauss=

** math.f***
   - =math.fsum=
   - =math.fmod=
   - =math.fabs=

* Datetime
** Finding Last Friday
   #+BEGIN_SRC python
     from dateutil.relativedelta import relativedelta
     from dateutil.rrule import FR
     d = datetime.now()
     print(d + relativedelta(weekday=FR(-1)))
   #+END_SRC

** Timezone
   #+BEGIN_SRC python
     import pytz
     d = datetime.now() # no timezone info
     print(d)
     # => 2018-12-21 17:14:01.258941

     shanghai = pytz.timezone('Asia/Shanghai')
     loc_d = shanghai.localize(d) # Localize the date for Shanghai
     print(loc_d)
     # => 2018-12-21 17:14:01.258941+08:00

     # Once the date has been localized, it can be converted to other time zones
     utc_d = loc_d.astimezone(pytz.utc)
     print(utc_d)
     # => 2018-12-21 09:14:01.258941+00:00
   #+END_SRC

   - ~datetime.replace~
   - ~datetime.astimezone~

* Iterator
** Manually Consuming an Iterator
   #+BEGIN_SRC python
     iterable = iter(range(5))  # Invokes range.__iter__()
     try:
         while True:
             line = next(iterable)  # Invokes iterable.__next__()
             print(line, end='')
     except StopIteration:
         pass

     # non exception version
     while True:
         line = next(iterable, None)
         if line is None:
             break
         print(line, end='')
   #+END_SRC
   - Python’s iterator protocol requires ~__iter__()~ to return a special iterator object that implements a ~__next__()~ method to carry out the actual iteration.
** Iterating Over Multi Sequences
   #+BEGIN_SRC python
     a = [1, 2, 3]
     b = ['w', 'x', 'y', 'z']

     for i in zip(a, b):
         print(i)
     #=> (1, 'w') (2, 'x') (3, 'y')

     from itertools import zip_longest
     for i in zip_longest(a, b):
         print(i)
     #=> (1, 'w') (2, 'x') (3, 'y') (None, 'z')
   #+END_SRC

** ~dropwhile~
   Drop all of the initial comment lines.

** Permutation & Combination
   - ~combinations~, ~permutations~, ~combinations_with_replacement~

** ~itertools.chain~
   Concatenate two iterables(copy-free)
** Data Processing Pipelines
** Flattening a Nested Sequence
   #+BEGIN_SRC python
     from collections import Iterable


     def flatten(items, ignore_types=(str, bytes)):
         for x in items:
             if isinstance(x, Iterable) and not isinstance(x, ignore_types):
                 yield from flatten(x)
             else:
                 yield x

     items = ['Dave', 'Paula', ['Thomas', 'Lewis']]
     for x in flatten(items):
         print(x)
   #+END_SRC
** Merge Two Sorted Iterables
   #+BEGIN_SRC python
     import heapq
     a = [1, 4, 7, 10]
     b = [2, 5, 6, 11]
     for c in heapq.merge(a, b):
         print(c)
   #+END_SRC
** ~iter()~
   <<iter>>
   ~iter()~ optionally accepts a zero-argument *callable* and *sentinel* (terminating) value as inputs.
   #+BEGIN_SRC python
     for chunk in iter(lambda: fs.read(10), ''):
         print(chunk)
   #+END_SRC
* I/O
** Encoding
   #+BEGIN_SRC python
     with open('somefile.txt', 'rt', encoding='latin-1') as f:
         ...
   #+END_SRC
   *latin-1* encoding is notable in that it will never produce a decoding error when reading text of a possibly unknown encoding.
   #+BEGIN_SRC python
     # Replace bad chars with Unicode U+fffd replacement char
     open('sample.txt', 'rt', encoding='ascii', errors='replace')

     # Ignore bad chars entirely
     open('sample.txt', 'rt', encoding='ascii', errors='ignore')
   #+END_SRC
** ~readinto~
   #+BEGIN_SRC python
     import array
     a = array.array('i', [0, 0, 0, 0, 0, 0, 0, 0])
     with open('data.bin', 'rb') as f:
         f.readinto(a)
   #+END_SRC
   ~readinto()~ fills the contents of an existing buffer
   - One caution with using ~f.readinto()~~ is that you must always make sure to check its return code, which is the number of bytes actually read.
** ~io.StringIO~, ~io.BytesIO~
** ~gzip.open~, ~bz2.open~
** Iterating Over Fixed-Sized Records
   #+BEGIN_SRC python
     from functools import partial

     RECORD_SIZE = 32

     with open('somefile.data', 'rb') as f:
         records = iter(partial(f.read, RECORD_SIZE), b'')
         for r in records:
             ...
   #+END_SRC
   - [[iter]]

** In-memory Modification
*** ~nmap~
    Use the ~mmap~ module to memory map files for random access to its contents or to make in-place modifications.
    - ~nmap~ also can be used to exchange data between interpreters

*** ~memoryview~
   #+BEGIN_SRC python
     buf = bytearray(b'Hello World')
     m1 = memoryview(buf)
     m2 = m1[-5:]
     #m2=> <memory at 0x100681390>
     m2[:] = b'WORLD'
     #buf=> bytearray(b'Hello WORLD')
   #+END_SRC

** ~os.path~
   #+BEGIN_SRC python
     os.path.basename(path)
     os.path.dirname(path)
     os.path.expanduser(path)
     os.path.splitext(path)  # Split the file extension
     os.path.exists(path)
     os.path.isfile(path) # isdir, islink
     os.path.realpath('/usr/local/bin/python3') # => '/usr/local/bin/python3.3'
     os.path.getsize() # getmtime
     os.listdir(dir)
   #+END_SRC
   - other module: ~glob~, ~fnmatch~ used for filename matching
** Changing Encoding of a File
   #+BEGIN_SRC python
     import io
     # decode a binary file
     with open('some_binary_file.bin', 'rb') as open_file:
         fs = io.TextIOWrapper(open_file, encoding='utf8')
         text = fs.read()

     # change encoding
     import sys
     sys.stdout.encoding  #=> 'UTF-8'
     # use its detach() method to remove the existing text encoding layer before replacing it with a new one
     sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='latin-1')
     sys.stdout.encoding #=> 'latin-1'
   #+END_SRC
   - layers on I/O:
   #+BEGIN_SRC python
     f = open('sample.txt', 'w')
     # a text-handling layer that encodes and decodes Unicode
     f # => <_io.TextIOWrapper name='sample.txt' mode='w' encoding='UTF-8'>

     # a buffered I/O layer that handles binary data
     f.buffer # => <_io.BufferedWriter name='sample.txt'>
     f.buffer.write(b'hello\n') # write bytes to a text file

     # io.FileIO is a raw file representing the low-level file descriptor in the operating system
     f.buffer.raw # => <_io.FileIO name='sample.txt' mode='wb'>
   #+END_SRC
   - ~detach~: disconnects the topmost layer of a file and returns the next lower layer.

** File Descriptor
   #+BEGIN_SRC python
     # Create a file object, but don't close underlying fd when done
     f = open(fd, 'wt', closefd=False)

     def echo_client(client_sock, addr):
         print('Got connection from', addr)

         # Make text-mode file wrappers for socket reading/writing, only works on Unix-based systems
         # Use the makefile() method of sockets instead to be cross platform
         client_in = open(client_sock.fileno(), 'rt', encoding='latin-1',
                              closefd=False)
         client_out = open(client_sock.fileno(), 'wt', encoding='latin-1',
                               closefd=False)

         # Echo lines back to the client using file I/O
         for line in client_in:
             client_out.write(line)
             client_out.flush()
         client_sock.close()
   #+END_SRC
** Temporary Files
   #+BEGIN_SRC python
     from tempfile import TemporaryFile, NamedTemporaryFile, TemporaryDirectory
     with TemporaryFile('w+t', encoding='utf-8', errors='ignore') as f:
         f.write('Hello World\n')

     with NamedTemporaryFile(
             'w+t', delete=False, prefix='mytemp', suffix='.txt', dir='/tmp') as f:
         print('filename is:', f.name)  #=> /tmp/mytemp2tmz4nl5.txt

     with TemporaryDirectory() as dirname:
         print('dirname is:', dirname)
   #+END_SRC

** Serializing Python Objects
   ~pickle~ is a Python-specific self-describing data encoding
*** Dealing with Multiple Objects
    #+BEGIN_SRC python
      import pickle
      with open('somedata', 'wb') as fs:
          pickle.dump([1, 2, 3, 4], fs)
          pickle.dump('hello', fs)

      with open('somedata', 'rb') as fs:
          pickle.load(fs) # => [1, 2, 3, 4]
          pickle.load(fs) # => hello
    #+END_SRC

*** Safety
    ~pickle.load()~ should never be used on untrusted data

*** User-defined Classes
    Certain kinds of objects can’t be pickled. These are typically objects that involve some sort of external system state, such as open files,
    open network connections, threads, processes, stack frames, and so forth. User-defined classes can sometimes work around these limitations
    by providing ~__getstate__()~ and ~__setstate__()~ methods
    - ~pickle.dump()~ will call ~__getstate__()~ to get an object that can be pickled

* Encoding
** csv
*** ~reader~
    #+BEGIN_SRC python
      from collections import namedtuple
      import re
      import csv
      with open('stock.csv') as f:
          f_csv = csv.reader(f)
          headings = next(f_csv)
          Row = namedtuple('Row', headings)
          for r in f_csv:
              row = Row(*r)
              # Process row
    #+END_SRC

*** ~DictReader~
   #+BEGIN_SRC python
     import csv
     with open('stocks.csv') as f:
         f_csv = csv.DictReader(f)
         for row in f_csv:
             # process row
             ...
   #+END_SRC

*** ~writer~
    - ~writer.writerow~ and ~writer.writerows~

*** ~DictWriter~
    - ~writer.writeheader~ and ~writer.writerows~
